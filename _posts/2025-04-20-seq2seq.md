---
title: Seq2seq
date: 2025-04-20 10:00:00 +0800
categories: [Paper Reading, Replicating]
tags: [Replicate, sequence]
---

Orginal Paper:  [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/pdf/1409.3215)

### 1. 引言

Seq2seq出现于2014年，当时深度学习的强大正在逐渐被人们所认识，并且随着诸如ReLU，Adam等深度学习技术逐渐出现并成熟，研究人员有意使用蓬勃发展的深度学习技术来挑战传统统计算法在序列任务中的地位。

本文的主要贡献是设计了一种以DNN（Deep Neural Network）为核心，同时能够进行端到端训练的结构。这个结构的主要优势是：

+ 对输入和输出的长度没有严格要求，能够开展通用的，不限长度的端到端序列训练
+ 编码器解码器互相独立，能够适配不同种类序列的任务
+ 编码器和解码器中间使用一个压缩的隐藏状态联系，使得解码器生成的内容可以参考所有的隐藏状态，而不需要和编码器输入的内容一一对应



### 2. Seq2seq的实现

文中关于RNN的定义如图：

![image-20250421152944825](assets/image-20250421152944825.png)

根据该定义我们可以很轻易地画出RNN的草图：

<img src="assets/IMG_0971.jpeg" alt="IMG_0971" style="zoom: 25%;" />

而具体实现的时候，因为编码器部分并不需要进行任何输出，所以也不需yh矩阵，实现如下：

```python
class Seq_1(nn.Module):
    def __init__(self):
        super(Seq_1, self).__init__()
        self.xh = nn.Sequential(
            nn.Linear(cfg.embedding_size, cfg.hidden_size*2),
            nn.ReLU(),
            nn.Linear(cfg.hidden_size*2, cfg.hidden_size//2),
            nn.ReLU(),
            nn.Linear(cfg.hidden_size//2, cfg.hidden_size)
        )
        self.hh = nn.Sequential(
            nn.Linear(cfg.hidden_size, cfg.hidden_size*2),
            nn.ReLU(),
            nn.Linear(cfg.hidden_size*2, cfg.hidden_size//2),
            nn.ReLU(),
            nn.Linear(cfg.hidden_size//2, cfg.hidden_size)
        )
        self.sigmoid = nn.Sigmoid()
        self.tanh = nn.Tanh()

    def forward(self, seq, input_lengths):
        batch_size, seq_len, embedding_size = seq.size()
        mask = torch.arange(seq_len, device=cfg.device).expand(batch_size, -1) < input_lengths.unsqueeze(1)

        hidden_state = torch.zeros(batch_size, cfg.hidden_size, device=cfg.device)

        for t in range(seq_len):
            token = seq[:,t,:]
            current_mask = mask[:, t].unsqueeze(1)
            temp_hidden_state = self.tanh(self.xh(token)+self.hh(hidden_state))
            hidden_state = torch.where(current_mask, temp_hidden_state, hidden_state)
            
        return hidden_state
```

因为模型训练的时候是以batch来训练的，但是batch中的每一个样本的长度并不是一样的，所以在每一个循环结束之后我们需要判断某样本在这个循环当中是否需要更新，以避免不合理的计算。同时我们将hidden_state初始化为全零矩阵

以下是解码器的实现：
```python
class Seq_2(nn.Module):
    def __init__(self):
        super(Seq_2, self).__init__()
        self.hh = nn.Sequential(
            nn.Linear(cfg.hidden_size, cfg.hidden_size*2),
            nn.ReLU(),
            nn.Linear(cfg.hidden_size*2, cfg.hidden_size//2),
            nn.ReLU(),
            nn.Linear(cfg.hidden_size//2, cfg.hidden_size),
            nn.ReLU()
        )
        self.hv = nn.Sequential(
            nn.Linear(cfg.hidden_size, cfg.hidden_size*2),
            nn.ReLU(),
            nn.Linear(cfg.hidden_size*2, cfg.hidden_size//2),
            nn.ReLU(),
            nn.Linear(cfg.hidden_size//2, cfg.vocab_size)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, hidden_state, decode_length):
        batch_size, _ = hidden_state.size()
        outputs = torch.zeros(batch_size, decode_length, cfg.vocab_size, device=cfg.device) # this tensor have a continual ram space, use it to avoid using torch.cat(), which cause O(n^2) complexity
        
        for t in range(decode_length):
            hidden_state = self.hh(hidden_state)
            outputs[:,t,:] = self.hv(hidden_state)
    
        return outputs
```

解码器的实现比编码器简单很多，并且多了hy矩阵用来将隐藏状态映射为输出。



### 3. 实验设计

正如Seq2seq设计之出所设想的一样，它几乎可以完成任何序列到序列任务的训练。我在这边设计了一个简单直观的任务，并且可以很好利用上Seq2seq的特性。



















